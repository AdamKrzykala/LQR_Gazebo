#!/usr/bin/env python3

import numpy as np
import rospy
from geometry_msgs.msg import Twist
from nav_msgs.msg import Odometry
import sys, select, os
import time
import math
if os.name == 'nt':
  import msvcrt
else:
  import tty, termios

robotPositionX = 0.0
robotPositionY = 0.0
robotOrientationZ = 0.0
readyToRace = False

BURGER_MAX_LIN_VEL = 0.22
BURGER_MAX_ANG_VEL = 2.84

WAFFLE_MAX_LIN_VEL = 0.26
WAFFLE_MAX_ANG_VEL = 1.82

LIN_VEL_STEP_SIZE = 0.01
ANG_VEL_STEP_SIZE = 0.1


# Supress scientific notation when printing NumPy arrays
np.set_printoptions(precision=3,suppress=True)

# Optional Variables
max_linear_velocity = 3.0 # meters per second
max_angular_velocity = 1.5708 # radians per second

def getB(yaw, deltat):
    B = np.array([  [np.cos(yaw)*deltat, 0],
                                    [np.sin(yaw)*deltat, 0],
                                    [0, deltat]])
    return B


def state_space_model(A, state_t_minus_1, B, control_input_t_minus_1):

    # These next 6 lines of code which place limits on the angular and linear
    # velocities of the robot car can be removed if you desire.
    control_input_t_minus_1[0] = np.clip(control_input_t_minus_1[0],
                                                                            -max_linear_velocity,
                                                                            max_linear_velocity)
    control_input_t_minus_1[1] = np.clip(control_input_t_minus_1[1],
                                                                            -max_angular_velocity,
                                                                            max_angular_velocity)
    state_estimate_t = (A @ state_t_minus_1) + (B @ control_input_t_minus_1)

    return state_estimate_t

def lqr(actual_state_x, desired_state_xf, Q, R, A, B, dt):

    # We want the system to stabilize at desired_state_xf.
    x_error = actual_state_x - desired_state_xf

    # Solutions to discrete LQR problems are obtained using the dynamic
    # programming method.
    # The optimal solution is obtained recursively, starting at the last
    # timestep and working backwards.
    # You can play with this number
    N = 50

    # Create a list of N + 1 elements
    P = [None] * (N + 1)

    Qf = Q

    # LQR via Dynamic Programming
    P[N] = Qf

    # For i = N, ..., 1
    for i in range(N, 0, -1):

        # Discrete-time Algebraic Riccati equation to calculate the optimal
        # state cost matrix
        P[i-1] = Q + A.T @ P[i] @ A - (A.T @ P[i] @ B) @ np.linalg.pinv(
            R + B.T @ P[i] @ B) @ (B.T @ P[i] @ A)

    # Create a list of N elements
    K = [None] * N
    u = [None] * N

    # For i = 0, ..., N - 1
    for i in range(N):

        # Calculate the optimal feedback gain K
        K[i] = -np.linalg.pinv(R + B.T @ P[i+1] @ B) @ B.T @ P[i+1] @ A

        u[i] = K[i] @ x_error

    # Optimal control input is u_star
    u_star = u[N-1]

    return u_star

def vels(target_linear_vel, target_angular_vel):
    return "currently:\tlinear vel %s\t angular vel %s " % (target_linear_vel,target_angular_vel)

def makeSimpleProfile(output, input, slop):
    if input > output:
        output = min( input, output + slop )
    elif input < output:
        output = max( input, output - slop )
    else:
        output = input

    return output

def constrain(input, low, high):
    if input < low:
      input = low
    elif input > high:
      input = high
    else:
      input = input

    return input

def checkLinearLimitVelocity(vel):
    if turtlebot3_model == "burger":
      vel = constrain(vel, -BURGER_MAX_LIN_VEL, BURGER_MAX_LIN_VEL)
    elif turtlebot3_model == "waffle" or turtlebot3_model == "waffle_pi":
      vel = constrain(vel, -WAFFLE_MAX_LIN_VEL, WAFFLE_MAX_LIN_VEL)
    else:
      vel = constrain(vel, -BURGER_MAX_LIN_VEL, BURGER_MAX_LIN_VEL)

    return vel

def checkAngularLimitVelocity(vel):
    if turtlebot3_model == "burger":
      vel = constrain(vel, -BURGER_MAX_ANG_VEL, BURGER_MAX_ANG_VEL)
    elif turtlebot3_model == "waffle" or turtlebot3_model == "waffle_pi":
      vel = constrain(vel, -WAFFLE_MAX_ANG_VEL, WAFFLE_MAX_ANG_VEL)
    else:
      vel = constrain(vel, -BURGER_MAX_ANG_VEL, BURGER_MAX_ANG_VEL)

    return vel

def pose_callback(msg):
    global robotPositionX, robotPositionY, robotOrientationZ
    global readyToRace
    robotPositionX = msg.pose.pose.position.x
    robotPositionY = msg.pose.pose.position.y
    robotOrientationZ = msg.pose.pose.orientation.z
    readyToRace = True


if __name__=="__main__":
    if os.name != 'nt':
        settings = termios.tcgetattr(sys.stdin)

    rospy.init_node('turtlebot3_lqr')
    rospy.Subscriber("odom", Odometry, pose_callback)

    pub = rospy.Publisher('cmd_vel', Twist, queue_size=10)

    turtlebot3_model = rospy.get_param("model", "burger")

    status = 0
    target_linear_vel   = 0.0
    target_angular_vel  = 0.0
    control_linear_vel  = 0.0
    control_angular_vel = 0.0


    # Let the time interval be 1.0 seconds
    dt = 0.1

    # Actual state
    # Our robot starts out at the origin (x=0 meters, y=0 meters), and
    # the yaw angle is 0 radians.
    actual_state_x = np.array([0.000,0.000,0.000])

    # Desired state [x,y,yaw angle]
    # [meters, meters, radians]
    desired_state_xf = np.array([1.000,1.000,math.pi/2])

    # A matrix
    # 3x3 matrix -> number of states x number of states matrix
    # Expresses how the state of the system [x,y,yaw] changes
    # from t-1 to t when no control command is executed.
    # Typically a robot on wheels only drives when the wheels are told to turn.
    # For this case, A is the identity matrix.
    # Note: A is sometimes F in the literature.
    A = np.array([  [1,  0,   0],
                                    [  0,1,   0],
                                    [  0,  0, 1]])

    # R matrix
    # The control input cost matrix
    # Experiment with different R matrices
    # This matrix penalizes actuator effort (i.e. rotation of the
    # motors on the wheels that drive the linear velocity and angular velocity).
    # The R matrix has the same number of rows as the number of control
    # inputs and same number of columns as the number of
    # control inputs.
    # This matrix has positive values along the diagonal and 0s elsewhere.
    # We can target control inputs where we want low actuator effort
    # by making the corresponding value of R large.
    R = np.array([[0.1,   0],  # Penalty for linear velocity effort
                [  0, 0.1]]) # Penalty for angular velocity effort

    # Q matrix
    # The state cost matrix.
    # Experiment with different Q matrices.
    # Q helps us weigh the relative importance of each state in the
    # state vector (X, Y, YAW ANGLE).
    # Q is a square matrix that has the same number of rows as
    # there are states.
    # Q penalizes bad performance.
    # Q has positive values along the diagonal and zeros elsewhere.
    # Q enables us to target states where we want low error by making the
    # corresponding value of Q large.
    Q = np.array([[0.639, 0, 0],  # Penalize X position error
                                [0, 1, 0],  # Penalize Y position error
                                [0, 0, 1]]) # Penalize YAW ANGLE heading error

    # Launch the robot, and have it move to the desired goal destination
    while(1):
        actual_state_x[0] = robotPositionX
        actual_state_x[1] = robotPositionY
        actual_state_x[2] = robotOrientationZ

        print(f'Current State = {actual_state_x}')
        print(f'Desired State = {desired_state_xf}')
        print(f'x = {robotPositionX}')

        state_error = actual_state_x - desired_state_xf
        state_error_magnitude = np.linalg.norm(state_error)
        print(f'State Error Magnitude = {state_error_magnitude}')

        B = getB(actual_state_x[2], dt)

        # LQR returns the optimal control input
        optimal_control_input = lqr(actual_state_x,
                                    desired_state_xf,
                                    Q, R, A, B, dt)

        print(f'Control Input = {optimal_control_input}')


        twist = Twist()
        control_linear_vel = makeSimpleProfile(control_linear_vel, target_linear_vel, (LIN_VEL_STEP_SIZE/2.0))
        twist.linear.x = optimal_control_input[0]; twist.linear.y = 0.0; twist.linear.z = 0.0

        control_angular_vel = makeSimpleProfile(control_angular_vel, target_angular_vel, (ANG_VEL_STEP_SIZE/2.0))
        twist.angular.x = 0.0; twist.angular.y = 0.0; twist.angular.z = optimal_control_input[1]

        pub.publish(twist)
        # We apply the optimal control to the robot
        # so we can get a new actual (estimated) state.
        # actual_state_x = state_space_model(A, actual_state_x, B, optimal_control_input)
        # Stop as soon as we reach the goal
        # Feel free to change this threshold value.
        if state_error_magnitude < 0.01:
            print("\nGoal Has Been Reached Successfully!")
            twist = Twist()
            control_linear_vel = makeSimpleProfile(control_linear_vel, target_linear_vel, (LIN_VEL_STEP_SIZE/2.0))
            twist.linear.x = 0.0; twist.linear.y = 0.0; twist.linear.z = 0.0

            control_angular_vel = makeSimpleProfile(control_angular_vel, target_angular_vel, (ANG_VEL_STEP_SIZE/2.0))
            twist.angular.x = 0.0; twist.angular.y = 0.0; twist.angular.z = 0.0

            pub.publish(twist)
            break
